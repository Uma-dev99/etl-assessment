
## ETL assessment project 
We created an ETL pipeline using Spark to process 
data and derive several analytics. The CSV contains data about enrolments from various
cities and states, including timestamps. The ETL pipeline should be optimized for
scalability and efficiency, taking into account data transformation, filtering, and
aggregation
<br>
## Project Structure 

- `main.py`: The main ETL pipeline script.
- `db.py`: Database connection and utility functions.
- `requirements.txt`: Python package dependencies.


## Setup
1. Clone the repository.
2. Navigate to the project directory.
3. Create a virtual environment (optional but recommended).
4. Install dependencies:
   ```bash
   pip install -r requirements.txt```

   
